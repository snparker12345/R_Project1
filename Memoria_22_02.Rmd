<!-- NOTES TO DEVELOP THE PROJECT: PABLO, SOPHIE, ALVARO 

Here you can write important notes you think must be considered for others when continuing with the project. The code starts in the nearest '---' line.

Basic sintax principles of R Markdown (cmd+click to go directly): https://rpubs.com/gustavomtzv/862622
https://markdown.es/sintaxis-markdown/#parrafos
-->

---
title: "GRUPO 6: MEMORIA AA1"
date: "01/02/2024"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción
En esta memoria se detallan los procesos y procedimientos empleados para la resolución de diferentes cuestiones sobre la base de datos "Gender Gap in Spanish Wikipedia". 

Primeramente es conveniente entender el problema a abordar.

## Brecha de género en Wikipedia.
Wikipedia es una enciclopedia de contenido libre que proyecta reunir todo el conocimiento humano. Se ubica en internet y se desarrolla gracias a voluntarios de todo el mundo; esto es, que la redactan y mantienen diversas personas en diferentes ubicaciones del globo. 

Sabemos que la población mundial se encuentra equitativamente dividida entre hombres y mujeres (hay una diferencia insignificante entre ambos grupos). Sin embargo, entre el 84 y el 91 por ciento de quienes editan las páginas de Wikipedia son varones, a pesar de que, como sabemos, son el 50% de la población mundial.

En 2011 la Fundación Wikimedia, organización matriz de Wikipedia sin ánimo de lucro, realizó una encuesta y los resultados fueron verdaderamente significativos:

<center>

![Fundación Wikimedia:https://es.wikipedia.org/wiki/Fundaci%C3%B3n_Wikimedia](/Users/pablopardo/Desktop/R_Studio/AA/Practica_AA1/img1.svg)

</center>\

Puede encontrar más información sobre la brecha de género en Wikipedia en el siguiente enlace:
https://es.wikipedia.org/wiki/Brecha_de_g%C3%A9nero_en_Wikipedia

**NOTA: Específicamente en nuestro problema trabajaremos con datos relativos a los editores de Wikipedia España.**


# Datos
La base de datos seleccionada para abordar el problema de disparidad de género en la redacción de Wikipedia España se puede encontrar el subsiguiente enlace: https://archive.ics.uci.edu/dataset/852/gender+gap+in+spanish+wp

Veamos en detalle las variables que componen el dataset:

* Gender: [TARGET] Indica el género codificado. Codificación: 0 para género desconocido, 1 para hombre y 2 para mujer.

* C_api: [TARGET] Indica el género según la API de WikiMedia (véase sección de introducción para comprender la relación de Wikimedia con el dataset en cuestión). Codificación: desconocido, hombre y mujer.

* C_man: [TARGET] Indica el género, el cual se extrae de la codificación del contenido de Wikipedia. Codificación: 1 hombre, 2 mujer, 3 género desconocido.

* E_NEds: Índice i del estrato. Índices: ij. Valores: 0,1,2,3.

* E_Bpag: Índice j del estrato. Índices: ij. Valores: 0,1,2,3.

* firstDay: Fecha de la primera edición en Wikipedia España (YYYYMMDDHHMMSS).

* lastDay: Fecha de la última edición en Wikipedia España (YYYYMMDDHHMMSS).

* NEds: Número total de ediciones.

* NDays: Número de días totales (último día-primer día +1)

* NActDays: Número de días con ediciones.

* NPages: Número de páginas diferentes editadas.

* NPcreated: Número de páginas creadas.

* pagesWomen: Número de ediciones en páginas relacionadas con la mujer.

* wikiprojWomen: Número de ediciones en proyectos 'Wiki' relacionados con la mujer.

* ns_user: Número de ediciones con namespace 'usuario'.

* ns_wikipedia: Número de ediciones con namespace 'Wikipedia'.

* ns_talk: Número de ediciones con namespace 'talk'.

* ns_userTalk: Número de ediciones con namespace 'usertalk'.

* ns_content: Número de ediciones con namespace 'pages'.

* wightIJ: Corrección de peso para estrato ij. <!--NO ENTIENDO AUN LAS UNIDADES DE ESTO NI LO QUE SIGNIFICA EXACTAMENTE-->

* NIJ: Numero de elementos en el estrato ij.


Nótese que el problema a resolver es de clasificación. Por tanto debemos convertir nuestra variable target a tipo binario. 


# Business understanding. 
Una vez hemos detectado las diferentes variables con las que vamos a trabajar, es fundamental comprender cómo estas se relacionan, entre qué valores se definen, si alguna presenta algún dato atípico...

Realizamos varias preguntas para intentar entender el problema y los valores de los datos contenidos:

¿Se realizan muchas ediciones en Wikipedia?
¿Cuántos proyectos 'Wiki' se realizan en total?
¿Cuántos días se suele tardar en realizar una edición?
¿Por qué existen diferentes 'namespace' para editar Wikipedia?

**OBJETIVO: Predecir el género del editor de una página de Wikipedia dada.**

# Data understanding.
Procedemos a cargar nuestros datos. Escogemos un único target: gender. Por tanto, eliminamos el resto de variales target (C_api y C_man), las cuales contienen datos similares. Además, eliminamos los datos categorizados como 'unknown' del target, reduciendo los niveles de nuestro factor en una unidad, de 3 a 2: 1 hombre, 2 mujer. 

## Librerías.

```{r LIBREÍAS}
library(caret)
library(ggplot2)
library(readr)
library(tidyverse)
library(viridis)
library(dplyr)
library(gridExtra)
library(ggplot2)
library(dplyr)
library(pdp) #pima dataset
library(corrplot)
library(palmerpenguins)
library(plotly)
library(car)
library(GGally)
library(MASS)
library(modeest)
```

## Lectura de datos.
```{r lectura, warning=FALSE} 
#Lectura de datos en csv
orig_df<-read_csv("datos/data.csv", show_col_types=FALSE)
#Eliminamos los datos con valor 'unknown' en la variable gender.
df_no_unknown<-orig_df[orig_df$gender !=0,]
#Eliminamos las variables target que no vamos a usar. Comprobamos el procedimiento: 
df<-subset(df_no_unknown, select=-c(C_api,C_man)); df

#Obtenemos la dimensión de la matriz con los que trabajaremos de ahora en adelante
dim(df)
n<- dim(df)[1]  # Así nombraremos las filas
p <- dim(df)[2] # Así nombraremos las columnas
```
Por tanto, tenemos  $n=$```r n```observaciones y $p=$```r p```variables en la base de datos. 
```{r np, warning=FALSE} 
n
p
```

## Division de los datos: train, test y validation.

Para este proyecto, se emplea una proporción de datos del **60%, 20%, 20%** para el entrenamiento, la prueba y la validación respectivamente. Para realizar la partición de los datos se ha empleado la función **createDataPartition** de la **librería caret.**

* Obtenemos nuestros datos de entrenamiento:
```{r DIVISION1, warning=FALSE} 

#Obtengo los índices para el 60% de los datos totales
indices_60 <- createDataPartition(df$gender, times = 1, p = 0.6)

#Se utiliza el 60% de los datos para entrenar el modelo
train_Data <- df[indices_60$Resample1,] # Selecciono todas las columnas
```

Dimensión de datos para el entrenamiento: ```r dim(train_Data)```

* Agrupamos los datos restantes para posteriormente volver a particionar.

```{r DIVISION2, warning=FALSE} 
#El signo menos (-) indica "no". Selecciono los datos que no he seleccionado antes: el 40% restante
data_test_val <- df[-indices_60$Resample1,] # Datos para dividir en prueba y validación

#Obtengo los índices para el 20% de los datos totales (50% de data_test_val)
indices_40 <- createDataPartition(data_test_val$gender, times = 1, p = 0.5)
```

* Obtenemos nuestros datos de prueba:
```{r DIVISION3, warning=FALSE} 

#El 20% de los datos se utiliza para probar el modelo.
test_Data <- data_test_val[indices_40$Resample1,] # Selecciono todas las columnas
```

Dimensión de datos para el test: ```r dim(test_Data)```

* Obtenemos nuestros datos de validación:
```{r DIVISION4, warning=FALSE} 

#Selecciono los datos que no he seleccionado antes: el 50% restante (20% del total)
val_Data <- data_test_val[-indices_40$Resample1,] # Selecciono todas las columnas
dim(val_Data)
```

Dimensión de datos para la validación : ```r dim(val_Data)```

* La suma de particiones debe ser igual a la dimensión total de los datos
```{r COMPR, warning=FALSE} 

#Verifico si las dimensiones coinciden. Objetivo: 3145 observaciones.
dim(train_Data) + dim(test_Data) + dim(val_Data)

```

Definimos como factores en R las variables **gender, E_NEds y E_Bpag.**
```{r FACTORS, warning=FALSE} 

train_Data$gender<-as.factor(train_Data$gender)
train_Data$E_NEds <-as.factor(train_Data$E_NEds)
train_Data$E_Bpag <-as.factor(train_Data$E_Bpag)
```
<!-- EN EL EDA NO SE PUEDEN ELIMINAR DATOS AUNQUE PAREZCAN ERRORES -->

# Análisis exploratorio de Datos
Poner estos comentarios cuando detallemos el analisis EDA de cada variable
¿Por qué para la variable wikiprojWomen tenemos un máximo de 949 y la gran mayoría de valores son 0 o similar?
¿No son muchas las ediciones 153193.0 (máximo de NEds)?

## Funciones de representación.

Para facilitar la lectura del código, se han definido diversas funciones de representación:
```{r FUNCIONES DE LOS DATOS, warning=FALSE} 

histogram = function(x_var, title= 'Histograma', x_label, y_label = "Frecuencia") {
  ggplot(train_Data, aes(x = {{x_var}})) +
    geom_histogram(bins = 40, color = 'black', fill = 'white') +
    geom_vline(aes(xintercept = mean({{x_var}})), color = "blue", linetype = "dashed", size = 1) +
    labs(title = title,
         x = x_label,
         y = y_label)
}
pdf = function(x_var, title='PDF', x_label, y_label = "Densidad") {
  ggplot(train_Data, aes(x = {{x_var}})) +
    geom_density() +
    labs(title = title,
         x = x_label,
         y = y_label)
}

boxplot = function(x_var, title = "Boxplot", x_label) {
  ggplot(train_Data, aes({{x_var}})) +
    geom_boxplot() +
    labs(title = title,
         x = x_label)
}
```
<!-- EL GRAFICO NO SALE A COLOR. VER COMO HACER ESTO-->
## [TARGET] Gender
Observemos nuestra variable gender. La cual tratamos como factor: 1 hombre, 2 mujer.
```{r TARGET, warning=FALSE} 

# Veamos la proporción de hombres y mujeres.
prop.table(table(train_Data$gender))

# Representamos un diagrama de barras.
ggplot(data = train_Data, aes(x = gender, fill = gender)) +
  geom_bar(aes(y = (..count..)/sum(..count..))) +
  scale_y_continuous(labels = scales::percent) +
  theme(legend.position = "none") +
  ylab("Frecuencia relativa") +
  xlab("Género")

```

## NDays.

```{r NDAys1, warning=FALSE} 
# Resumen de la variable NDays en train_Data.
summary(train_Data$NDays)
```
*El primer cuartil toma un valor bajo (806) por lo que tenemos una apreciable concentración de datos con valores bajos. Además, la media es algo superior a la mediana, i.e, la distribución presentará una ligera asimetría a la derecha.*

```{r NDAys2, warning=FALSE} 
# Veamos la forma de su distribución con un histograma. La línea azul representa la media.
NDays_hist<-histogram(NDays, x_label= "Último día-Primer día +1"); NDays_hist
```
</center>\
*Los datos no provienen de una distribución normal.*

```{r NDAys3, warning=FALSE} 
# Veamos su función de densidad de probabilidad.
NDays_pdf<- pdf(NDays, x_label='Último día-Primer día +1'); NDays_pdf
```
</center>\
*La probabilidad se encuentra homogéneamente distribuida, aunque hay una gran concentración como  esperábamos entre los valores 0 y 1500.*

```{r NDAys4, warning=FALSE} 
# Boxplot.
bp_NDays<-boxplot(NDays, x_label='Último día-Primer día +1'); bp_NDays
```
</center>\
*No se observan datos atípicos*.


## NActDays, NPages y NPcreated.

Estudiaremos en conjunto estas variables al presentar una distribución similar. Se obtienen conclusiones similares de todas ellas.

```{r NActDAys0, warning=FALSE} 
# Resumen de la variable NActDays en train_Data. 
summary(train_Data$NActDays)
```
*El primer cuartil toma un valor bajo (24), observamos un máximo de 3346 y una media de 53. Por tanto, tenemos una notoria concentración de datos con valores bajos. Además, la media es bastante superior a la mediana, i.e, la distribución presentará una notable asimetría a la derecha.*

```{r NActDAys1, warning=FALSE} 

#NActDAys - Estimación unimodal
mlv(train_Data$NActDays, method = "meanshift")
```
*La moda estimada tiene un valor de 27.19 lo que ratifica nuestra sospecha de que la distribución tendrá una larga cola derecha.*

```{r NActDAys2, warning=FALSE} 

# Resumen de la variable NPages en train_Data. 
summary(train_Data$NPages)
```
*Conclusiones similares a las de la variable NActDays*

```{r NActDAys3, warning=FALSE} 

# Resumen de la variable NPcreated en train_Data. 
summary(train_Data$NPcreated)
```
*En este caso encontramos valores más bajos, aunque, al igual que las otras dos variables, la distribución tendrá una gran asimetría a la derecha al concentrarse los datos en los valores bajos (1Q= 1.0)*

Observemos sus distribuciones.
```{r NActDAys4, warning=FALSE} 

# NActDays - Veamos la forma de su distribución con un histograma
NActDays_hist<-histogram(NActDays, x_label='Días con ediciones'); NActDays_hist

# NPages - Veamos la forma de su distribución con un histograma
NPages_hist<-histogram(NPages, x_label='Páginas diferentes editadas'); NPages_hist

# NPcreated - Veamos la forma de su distribución con un histograma 
NPcreated_hist<-histogram(NPcreated, x_label='Páginas creadas'); NPcreated_hist
```
</center>\
*Como se puede observar, todas las distribuciones presentan baja uniformidad y una notable asimetría a la derecha.*

```{r NActDAys5, warning=FALSE} 

# NActDays - Veamos su función de densidad de probabilidad.
NActDays_pdf<- pdf(NActDays, x_label='Días con ediciones'); NActDays_pdf

# NPages - Veamos su función de densidad de probabilidad.
NPages_pdf<-pdf(NPages, x_label='Páginas diferentes editadas'); NPages_pdf

# NPcreated - Veamos su función de densidad de probabilidad.
NPcreated_pdf<-pdf(NPcreated, x_label='Páginas creadas'); NPcreated_pdf
```
</center>\
*La probabilidad siempre se encuentra concentrada en los valores bajos. Esto es esperado, considerando los datos analizados anteriormente.*

```{r NActDAys6, warning=FALSE} 

# NActDays - Diagrama de caja.
bp_NActDays<-boxplot(NActDays, x_label='Días con ediciones'); bp_NActDays
```
</center>\
*Observamos muchos datos superiores a Q3 + 1.5RI. Sin embargo, solo se considerarían datos atípicos aquellos con valor superior a 3000 aproximadamente.*

```{r NActDAys7, warning=FALSE} 

# NPages - Diagrama de caja.
bp_NPages<-boxplot(NPages, x_label='Páginas diferentes editadas'); bp_NPages
```
</center>\
*Observamos muchos datos superiores a Q3 + 1.5RI. Sin embargo, solo se considerarían datos atípicos aquellos con valor superior a 40000 aproximadamente.*

```{r NActDAys8, warning=FALSE} 

# NPcreated - Diagrama de caja.
bp_NPcreated<-boxplot(NPcreated, x_label='Páginas creadas'); bp_NPcreated
```
</center>\

*Observamos un par de datos atípicos a partir del valor 2000. Especialmente, cabe destacar el valor máximo de la función, el cual es superior a 6000.*

*Esta variable indica el número de páginas creadas. Puede haber sido dato introducido erróneamente, aunque podría  ser verídico, y no parece pertenecer a ninguna de las variables cercanas, i.e NPages o pagesWomen.*

Transformemos los datos para poder trabajar con una distribución con mejores propiedades. **Véase que NPcreated, al ser una variable esparsa, no acepta una transformación box cox.**

```{r NActDAys9, warning=FALSE} 

# NActDays - Transformación de datos (box cox).
boxcox(lm(train_Data$NActDays ~ 1)) 
```
</center>\
Obtenemos el valor de lambda=0 --> TRANSFORMACIÓN: log10(x). **Esta transformación también será la empleada para los datos de Npages.**

```{r NActDAys10, warning=FALSE} 

new_NActDays<- log10(train_Data$NActDays)
#Representamos el histograma con los datos transformados
histogram(new_NActDays, x_label='Días con ediciones')
```
</center>\

```{r NActDAys11, warning=FALSE} 

new_NPages<- log10(train_Data$NPages)
#Representamos el histograma con los datos transformados
histogram(new_NPages, x_label='Páginas diferentes editadas')

```

## pagesWomen

```{r pagesWomen1, warning=FALSE} 
# Resumen de la variable pagesWomen en train_Data.
summary(train_Data$pagesWomen)
```
</center>\
*Podemos apreciar que, tanto el primer como el tercer cuartil, tienen un valor de 0. Además, la mediana es 0 y la media está muy cercana a 0.Por tanto, estamos ante una **variable dispersa**, puesto que la mayoría de valores son 0. *

```{r pagesWomen2, warning=FALSE} 

# Veamos la forma de su distribución con un histograma 
pagesWomen_hist<-histogram(pagesWomen, x_label='Ediciones en pág. Mujer'); pagesWomen_hist
```
</center>\
*Confirmamos nuestra conclusión anterior*
```{r pagesWomen3, warning=FALSE} 

# Veamos su función de densidad de probabilidad.
pagesWomen_pdf<-pdf(pagesWomen, x_label='Ediciones en pág. Mujer'); pagesWomen_pdf
```
</center>\
*La probabilidad se encuentra únicamente concentrada en los valores bajos. Esto es esperado, considerando los datos del summary analizado anteriormente.*

```{r pagesWomen4, warning=FALSE} 

# Diagrama de caja.
bp_pagesWomen<-boxplot(pagesWomen, x_label='Ediciones en pág. Mujer'); bp_pagesWomen
```
</center>\
*Encontramos un par de datos atípicos entre los valores 50 y 100, aunque el valor atípico más destacable se encuentra totalmente aislado por encima del valor 150. Este dato es el máximo que se indica en el summary: 185000.*

*Teniendo en cuenta que se trata de una variable que incluye información sobre el número de ediciones en páginas relacionadas con la mujer, parece un error.* 

*Otra opción sería considerar que ese dato se encuentra ahí debido a un error humano y que realmente pertenece a otra variable. En el rango de la variable anterior a pagesWomen, i.e NPcreated, un valor de 185 podría encajar (en ningún caso 185000) pero NPcreated no tiene ningún valor faltante. Esto nos hace pensar que no acepta ningún valor añadido.*

*Por otro lado, la siguiente variable a pagesWomen, i.e wikiprojWomen, tiene un comportamiento muy similar a pagesWomen, por lo que en ningún caso aceptaría ese dato.*

*Teniendo en consideración lo mencionado anteriormente, se cambia el dato por 0, puesto que es el valor más frecuente, coincide con la media y está cercano a la media.*

**Véase que NPcreated al ser una variable esparsa no acepta una transformación box cox.**




 

<!-- #EDA MULTIVARIANTE (Habría que meterlo aquí) -->




# Técnicas de reducción de la dimensionalidad

## PCA

En nuestro dataset encontramos 


# Modelos de Aprendizaje Automático


## ML no supervisado


## ML Supervisado


<!-- ESTO ES UN COMENTARIO -->

<!-- UN # TITULO, DOS # SUBTITULO -->

<!-- AGRUPAR BOXPLOT SI LAS VARIABLES SON PARECIDAS PARA COMPARAR 2 A 2 
HACER GGPAIRS CON VARIABLES RELACIONADAS CON LOS DÍAS PARA VER SU CORRELACION Y DEMÁS-->


